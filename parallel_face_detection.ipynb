{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rp61jnRHDELv"
   },
   "source": [
    "# Parallelization and Performance Optimization on Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IUVQzmsfc7Z1",
    "outputId": "3c10f0ed-1960-42a4-f64a-3e5d8597fc59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (7.1.2)\n"
     ]
    }
   ],
   "source": [
    "pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WSJE9Gym6J85",
    "outputId": "92efa053-c565-4a98-e3d4-b0ce968cf345"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy==1.1.0\n",
      "  Downloading scipy-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (31.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 31.2 MB 45.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from scipy==1.1.0) (1.19.5)\n",
      "Installing collected packages: scipy\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.4.1\n",
      "    Uninstalling scipy-1.4.1:\n",
      "      Successfully uninstalled scipy-1.4.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pymc3 3.11.4 requires scipy>=1.2.0, but you have scipy 1.1.0 which is incompatible.\n",
      "plotnine 0.6.0 requires scipy>=1.2.0, but you have scipy 1.1.0 which is incompatible.\n",
      "jax 0.2.25 requires scipy>=1.2.1, but you have scipy 1.1.0 which is incompatible.\n",
      "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
      "Successfully installed scipy-1.1.0\n"
     ]
    }
   ],
   "source": [
    "pip install scipy==1.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dLgy0zZsWHjp"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Javascript\n",
    "from google.colab.output import eval_js\n",
    "from base64 import b64decode\n",
    "\n",
    "def take_photo(filename, quality=0.8):\n",
    "  js = Javascript('''\n",
    "    async function takePhoto(quality) {\n",
    "      const div = document.createElement('div');\n",
    "      const capture = document.createElement('button');\n",
    "      capture.textContent = 'Capture';\n",
    "      div.appendChild(capture);\n",
    "\n",
    "      const video = document.createElement('video');\n",
    "      video.style.display = 'block';\n",
    "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
    "\n",
    "      document.body.appendChild(div);\n",
    "      div.appendChild(video);\n",
    "      video.srcObject = stream;\n",
    "      await video.play();\n",
    "\n",
    "      // Resize the output to fit the video element.\n",
    "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
    "\n",
    "      // Wait for Capture to be clicked.\n",
    "      await new Promise((resolve) => capture.onclick = resolve);\n",
    "\n",
    "      const canvas = document.createElement('canvas');\n",
    "      canvas.width = video.videoWidth;\n",
    "      canvas.height = video.videoHeight;\n",
    "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
    "      stream.getVideoTracks()[0].stop();\n",
    "      div.remove();\n",
    "      return canvas.toDataURL('image/jpeg', quality);\n",
    "    }\n",
    "    ''')\n",
    "  display(js)\n",
    "  data = eval_js('takePhoto({})'.format(quality))\n",
    "  binary = b64decode(data.split(',')[1])\n",
    "  with open(filename, 'wb') as f:\n",
    "    f.write(binary)\n",
    "  return filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R49_gF9ORDgP"
   },
   "source": [
    "**Parallel Execution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OWToWGkaYAKN"
   },
   "outputs": [],
   "source": [
    "import scipy.misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "id": "Au9m6Ri8u3RN",
    "outputId": "9f1df51d-c446-415b-a502-f175a511f2e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function takePhoto(quality) {\n",
       "      const div = document.createElement('div');\n",
       "      const capture = document.createElement('button');\n",
       "      capture.textContent = 'Capture';\n",
       "      div.appendChild(capture);\n",
       "\n",
       "      const video = document.createElement('video');\n",
       "      video.style.display = 'block';\n",
       "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
       "\n",
       "      document.body.appendChild(div);\n",
       "      div.appendChild(video);\n",
       "      video.srcObject = stream;\n",
       "      await video.play();\n",
       "\n",
       "      // Resize the output to fit the video element.\n",
       "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
       "\n",
       "      // Wait for Capture to be clicked.\n",
       "      await new Promise((resolve) => capture.onclick = resolve);\n",
       "\n",
       "      const canvas = document.createElement('canvas');\n",
       "      canvas.width = video.videoWidth;\n",
       "      canvas.height = video.videoHeight;\n",
       "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
       "      stream.getVideoTracks()[0].stop();\n",
       "      div.remove();\n",
       "      return canvas.toDataURL('image/jpeg', quality);\n",
       "    }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to 123.jpg\n",
      "(480, 640)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function takePhoto(quality) {\n",
       "      const div = document.createElement('div');\n",
       "      const capture = document.createElement('button');\n",
       "      capture.textContent = 'Capture';\n",
       "      div.appendChild(capture);\n",
       "\n",
       "      const video = document.createElement('video');\n",
       "      video.style.display = 'block';\n",
       "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
       "\n",
       "      document.body.appendChild(div);\n",
       "      div.appendChild(video);\n",
       "      video.srcObject = stream;\n",
       "      await video.play();\n",
       "\n",
       "      // Resize the output to fit the video element.\n",
       "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
       "\n",
       "      // Wait for Capture to be clicked.\n",
       "      await new Promise((resolve) => capture.onclick = resolve);\n",
       "\n",
       "      const canvas = document.createElement('canvas');\n",
       "      canvas.width = video.videoWidth;\n",
       "      canvas.height = video.videoHeight;\n",
       "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
       "      stream.getVideoTracks()[0].stop();\n",
       "      div.remove();\n",
       "      return canvas.toDataURL('image/jpeg', quality);\n",
       "    }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to 2nd.jpg\n",
      "(480, 640)\n",
      "Photo norm: 24889.701960784314 / per pixel: 0.1338134436583513\n",
      "Zero norm: 175549.0 / per pixel: 0.9437966054310952\n",
      "13.38134436583513\n",
      "Images are of the Same person\n",
      "Time taken for parallel program is  0.08734381385585352\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import concurrent.futures\n",
    "import Time   \n",
    "#import imageio\n",
    "import time\n",
    "import cv2 as cv\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from scipy import misc\n",
    "import datetime\n",
    "import sys\n",
    "from scipy.misc import toimage\n",
    "from scipy.misc.pilutil import imread\n",
    "from scipy.linalg import norm\n",
    "from scipy import sum, average\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "print(num_cores)\n",
    "filename = take_photo(\"123.jpg\")\n",
    "print('Saved to {}'.format(filename))\n",
    "img = cv.imread('123.jpg')\n",
    "\n",
    "face = misc.imread('123.jpg', cv.IMREAD_UNCHANGED)\n",
    "print (face.shape)\n",
    "face_cascade = cv.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "img = cv.imread('123.jpg')\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "(x, y, w, h)=(0,0,0,0)\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "frame = img[y:y+h, x:x+w]\n",
    "cv.imwrite('face.jpg', frame)\n",
    "\n",
    "time1=time.time()\n",
    "\n",
    "img = cv.imread(\"face.jpg\")\n",
    "H,W = img.shape[:2]\n",
    "gray = np.zeros((H,W), np.uint8)\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    for i in range(H):\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            for j in range(W):\n",
    "                gray[i,j] = np.clip(0.07 * img[i,j,0]  + 0.72 * img[i,j,1] + 0.21 * img[i,j,2], 0, 255)\n",
    "cv.imwrite('facegray.jpg', gray)\n",
    "\n",
    "filename = take_photo(\"2nd.jpg\")\n",
    "print('Saved to {}'.format(filename))\n",
    "img = cv.imread('2nd.jpg')\n",
    "a = datetime.datetime.now()\n",
    "\n",
    "face = misc.imread('2nd.jpg', cv.IMREAD_UNCHANGED)\n",
    "print (face.shape)\n",
    "face_cascade = cv.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "img = cv.imread('2nd.jpg')\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "frame = img[y:y+h, x:x+w]\n",
    "cv.imwrite('FaceinDataBase.jpg', frame)\n",
    "\n",
    "img = cv.imread(\"FaceinDataBase.jpg\")\n",
    "H,W = img.shape[:2]\n",
    "gray = np.zeros((H,W), np.uint8)\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    for i in range(H):\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            for j in range(W):\n",
    "                gray[i,j] = np.clip(0.07 * img[i,j,0]  + 0.72 * img[i,j,1] + 0.21 * img[i,j,2], 0, 255)\n",
    "cv.imwrite('FaceinDataBasegray.jpg', gray)\n",
    "cv.waitKey()\n",
    "\n",
    "def normalize(arr):\n",
    "  rng = arr.max()-arr.min()\n",
    "  amin = arr.min()\n",
    "  return (arr-amin)*255/rng\n",
    "\n",
    "def compare_images(img1, img2):\n",
    "  img1 = normalize(img1)\n",
    "  img2 = normalize(img2)\n",
    "  diff = img1 - img2 \n",
    "  m_norm = sum(abs(diff))\n",
    "  z_norm = norm(diff.ravel(), 0) \n",
    "  return (m_norm, z_norm)\n",
    "\n",
    "def compareimagepercntage(n_m,img1):\n",
    "  return n_m/img1.size*100<27.5\n",
    "img1=cv.imread(\"FaceinDataBasegray.jpg\")\n",
    "img2=cv.imread(\"facegray.jpg\")\n",
    "x=len(np.array(img1))\n",
    "y=len(np.array(img2))\n",
    "\n",
    "width = int(img1.shape[1]*y/x)\n",
    "height = int(img1.shape[0]*y/x)\n",
    "dim = (width, height)\n",
    "# resize image\n",
    "resized = cv.resize(img, dim, interpolation = cv.INTER_AREA)\n",
    "cv.imwrite('NewSizedImageGray.jpg',resized) \n",
    "\n",
    "img1=cv.imread(\"NewSizedImageGray.jpg\")\n",
    "n_m, n_0 = compare_images(img1, img2)\n",
    "print(\"Photo norm:\", n_m, \"/ per pixel:\", n_m/img1.size)\n",
    "print(\"Zero norm:\", n_0, \"/ per pixel:\", n_0*1.0/img1.size)\n",
    "\n",
    "if(compareimagepercntage(n_m,img1)):\n",
    "  print(n_m/img1.size*100)\n",
    "  print(\"Images are of the Same person\")\n",
    "else:\n",
    "  print(n_m/img1.size*100)\n",
    "  print(\"Images Are of Different People\")\n",
    "\n",
    "time2=time.time()\n",
    "par_time=Time.timediffpar(time2,time1)\n",
    "print(\"Time taken for parallel program is \",par_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cnnvX3vD7bPq"
   },
   "source": [
    "**Serial Execution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "id": "fpmSWXVXuYHY",
    "outputId": "c536552f-0eb0-49ae-a028-2c1873685c93"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function takePhoto(quality) {\n",
       "      const div = document.createElement('div');\n",
       "      const capture = document.createElement('button');\n",
       "      capture.textContent = 'Capture';\n",
       "      div.appendChild(capture);\n",
       "\n",
       "      const video = document.createElement('video');\n",
       "      video.style.display = 'block';\n",
       "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
       "\n",
       "      document.body.appendChild(div);\n",
       "      div.appendChild(video);\n",
       "      video.srcObject = stream;\n",
       "      await video.play();\n",
       "\n",
       "      // Resize the output to fit the video element.\n",
       "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
       "\n",
       "      // Wait for Capture to be clicked.\n",
       "      await new Promise((resolve) => capture.onclick = resolve);\n",
       "\n",
       "      const canvas = document.createElement('canvas');\n",
       "      canvas.width = video.videoWidth;\n",
       "      canvas.height = video.videoHeight;\n",
       "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
       "      stream.getVideoTracks()[0].stop();\n",
       "      div.remove();\n",
       "      return canvas.toDataURL('image/jpeg', quality);\n",
       "    }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to 123.jpg\n",
      "(480, 640)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function takePhoto(quality) {\n",
       "      const div = document.createElement('div');\n",
       "      const capture = document.createElement('button');\n",
       "      capture.textContent = 'Capture';\n",
       "      div.appendChild(capture);\n",
       "\n",
       "      const video = document.createElement('video');\n",
       "      video.style.display = 'block';\n",
       "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
       "\n",
       "      document.body.appendChild(div);\n",
       "      div.appendChild(video);\n",
       "      video.srcObject = stream;\n",
       "      await video.play();\n",
       "\n",
       "      // Resize the output to fit the video element.\n",
       "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
       "\n",
       "      // Wait for Capture to be clicked.\n",
       "      await new Promise((resolve) => capture.onclick = resolve);\n",
       "\n",
       "      const canvas = document.createElement('canvas');\n",
       "      canvas.width = video.videoWidth;\n",
       "      canvas.height = video.videoHeight;\n",
       "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
       "      stream.getVideoTracks()[0].stop();\n",
       "      div.remove();\n",
       "      return canvas.toDataURL('image/jpeg', quality);\n",
       "    }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to 2nd.jpg\n",
      "Photo norm: 21643.160784313724 / per pixel: 0.12953150905100141\n",
      "Zero norm: 157824.0 / per pixel: 0.9445561620224073\n",
      "Images Are of same Person!!!!!Hurray...!!!\n",
      "Time For Serial Execution -  0.7796968967109902\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import Time   \n",
    "import time\n",
    "import cv2 as cv\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from scipy import misc\n",
    "import datetime\n",
    "import sys\n",
    "from scipy.misc import imread\n",
    "from scipy.linalg import norm\n",
    "from scipy import sum, average\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "\n",
    "\n",
    "filename = take_photo(\"123.jpg\")\n",
    "print('Saved to {}'.format(filename))\n",
    "img = cv.imread('123.jpg')\n",
    "\n",
    "face = misc.imread('123.jpg', cv.IMREAD_UNCHANGED)\n",
    "print (face.shape)\n",
    "face_cascade = cv.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "img = cv.imread('123.jpg')\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "(x, y, w, h)=(0,0,0,0)\n",
    "for (x, y, w, h) in faces:\n",
    "    cv.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "frame = img[y:y+h, x:x+w]\n",
    "cv.imwrite('facecircledimg.jpg', img)\n",
    "\n",
    "cv.imwrite('face.jpg', frame)\n",
    "\n",
    "time1=time.time()\n",
    "\n",
    "img = cv.imread(\"face.jpg\")\n",
    "H,W = img.shape[:2]\n",
    "gray = np.zeros((H,W), np.uint8)\n",
    "for i in range(H):\n",
    "    for j in range(W):\n",
    "        gray[i,j] = np.clip(0.07 * img[i,j,0]  + 0.72 * img[i,j,1] + 0.21 * img[i,j,2], 0, 255)\n",
    "cv.imwrite('facegray.jpg', gray)\n",
    "\n",
    "\n",
    "\n",
    "filename = take_photo(\"2nd.jpg\")\n",
    "print('Saved to {}'.format(filename))\n",
    "img = cv.imread('2nd.jpg')\n",
    "face_cascade = cv.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "img = cv.imread('2nd.jpg')\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "for (x, y, w, h) in faces:\n",
    "    cv.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "frame = img[y:y+h, x:x+w]\n",
    "cv.imwrite('Face2.jpg', frame)\n",
    "cv.imwrite('facecircledimg1.jpg', img)\n",
    "\n",
    "\n",
    "img = cv.imread(\"Face2.jpg\")\n",
    "H,W = img.shape[:2]\n",
    "gray = np.zeros((H,W), np.uint8)\n",
    "for i in range(H):\n",
    "    for j in range(W):\n",
    "        gray[i,j] = np.clip(0.07 * img[i,j,0]  + 0.72 * img[i,j,1] + 0.21 * img[i,j,2], 0, 255)\n",
    "cv.imwrite('Facegray2.jpg', gray)\n",
    "cv.waitKey()\n",
    "\n",
    "def normalize(arr):\n",
    "    rng = arr.max()-arr.min()\n",
    "    amin = arr.min()\n",
    "    return (arr-amin)*255/rng\n",
    "\n",
    "def compare_images(img1, img2):\n",
    "    img1 = normalize(img1)\n",
    "    img2 = normalize(img2)\n",
    "    diff = img1 - img2 \n",
    "    m_norm = sum(abs(diff))\n",
    "    z_norm = norm(diff.ravel(), 0) \n",
    "    return (m_norm, z_norm)\n",
    "\n",
    "img1=cv.imread(\"Facegray2.jpg\")\n",
    "img2=cv.imread(\"facegray.jpg\")\n",
    "x=len(np.array(img1))\n",
    "y=len(np.array(img2))\n",
    "\n",
    "width = int(img1.shape[1]*y/x)\n",
    "height = int(img1.shape[0]*y/x)\n",
    "dim = (width, height)\n",
    "# resize image\n",
    "resized = cv.resize(img, dim, interpolation = cv.INTER_AREA)\n",
    "cv.imwrite('NewSizedImageGray.jpg',resized) \n",
    "\n",
    "img1=cv.imread(\"NewSizedImageGray.jpg\")\n",
    "n_m, n_0 = compare_images(img1, img2)\n",
    "print(\"Photo norm:\", n_m, \"/ per pixel:\", n_m/img1.size)\n",
    "print(\"Zero norm:\", n_0, \"/ per pixel:\", n_0*1.0/img1.size)\n",
    "\n",
    "if(n_m/img1.size*100<25):\n",
    "    print(\"Images Are of same Person!!!!!Hurray...!!!\")\n",
    "else:\n",
    "    print(\"Images Are of Different People\")\n",
    "\n",
    "time2=time.time()\n",
    "ser_time=Time.timediffparsr(time2,time1)\n",
    "print(\"Time For Serial Execution - \",ser_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zPLL7N5H2I4j",
    "outputId": "32381dd9-ddd2-4e8c-fbd7-fc5992a2fcdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speedup Ratio for the program is 8.926755797471252\n"
     ]
    }
   ],
   "source": [
    "print(\"Speedup Ratio for the program is\",ser_time/par_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UI-ispzF7ON8"
   },
   "source": [
    "**Compare 2 photos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0N6OyFIM6_CB"
   },
   "source": [
    "Serial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fkTpk_i06yoZ",
    "outputId": "c2526e73-622b-4f40-a037-392a00bb82ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 500)\n",
      "(847, 696)\n",
      "Photo norm: 85799.36754759874 / per pixel: 0.31566747809111284\n",
      "Zero norm: 271797.0 / per pixel: 0.9999779251884637\n",
      "31.566747809111284\n",
      "Images Are of Different People\n",
      "Time For Serial Execution -  0.7719303457472553\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import Time   \n",
    "import time\n",
    "import cv2 as cv\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from scipy import misc\n",
    "import datetime\n",
    "import sys\n",
    "from scipy.misc import imread\n",
    "from scipy.linalg import norm\n",
    "from scipy import sum, average\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "face = misc.imread('photo1.jpg', cv.IMREAD_UNCHANGED)\n",
    "print (face.shape)\n",
    "face_cascade = cv.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "img = cv.imread('photo1.jpg')\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "(x, y, w, h)=(0,0,0,0)\n",
    "for (x, y, w, h) in faces:\n",
    "    cv.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "frame = img[y:y+h, x:x+w]\n",
    "cv.imwrite('facecircledimg.jpg', img)\n",
    "\n",
    "cv.imwrite('Face.jpg', frame)\n",
    "\n",
    "time1=time.time()\n",
    "\n",
    "img = cv.imread(\"Face.jpg\")\n",
    "H,W = img.shape[:2]\n",
    "gray = np.zeros((H,W), np.uint8)\n",
    "for i in range(H):\n",
    "    for j in range(W):\n",
    "        gray[i,j] = np.clip(0.07 * img[i,j,0]  + 0.72 * img[i,j,1] + 0.21 * img[i,j,2], 0, 255)\n",
    "cv.imwrite('Facegray.jpg', gray)\n",
    "\n",
    "\n",
    "\n",
    "face = misc.imread('photo2.jpg', cv.IMREAD_UNCHANGED)\n",
    "print (face.shape)\n",
    "face_cascade = cv.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "img = cv.imread('photo2.jpg')\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "for (x, y, w, h) in faces:\n",
    "    cv.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "frame = img[y:y+h, x:x+w]\n",
    "cv.imwrite('Face2.jpg', frame)\n",
    "cv.imwrite('facecircledimg1.jpg', img)\n",
    "\n",
    "\n",
    "img = cv.imread(\"Face2.jpg\")\n",
    "H,W = img.shape[:2]\n",
    "gray = np.zeros((H,W), np.uint8)\n",
    "for i in range(H):\n",
    "    for j in range(W):\n",
    "        gray[i,j] = np.clip(0.07 * img[i,j,0]  + 0.72 * img[i,j,1] + 0.21 * img[i,j,2], 0, 255)\n",
    "cv.imwrite('Facegray2.jpg', gray)\n",
    "cv.waitKey()\n",
    "\n",
    "def normalize(arr):\n",
    "    rng = arr.max()-arr.min()\n",
    "    amin = arr.min()\n",
    "    return (arr-amin)*255/rng\n",
    "\n",
    "def compare_images(img1, img2):\n",
    "    img1 = normalize(img1)\n",
    "    img2 = normalize(img2)\n",
    "    diff = img1 - img2 \n",
    "    m_norm = sum(abs(diff))\n",
    "    z_norm = norm(diff.ravel(), 0) \n",
    "    return (m_norm, z_norm)\n",
    "\n",
    "img1=cv.imread(\"Facegray2.jpg\")\n",
    "img2=cv.imread(\"Facegray.jpg\")\n",
    "x=len(np.array(img1))\n",
    "y=len(np.array(img2))\n",
    "\n",
    "width = int(img1.shape[1]*y/x)\n",
    "height = int(img1.shape[0]*y/x)\n",
    "dim = (width, height)\n",
    "# resize image\n",
    "resized = cv.resize(img, dim, interpolation = cv.INTER_AREA)\n",
    "cv.imwrite('NewSizedImageGray.jpg',resized) \n",
    "\n",
    "img1=cv.imread(\"NewSizedImageGray.jpg\")\n",
    "n_m, n_0 = compare_images(img1, img2)\n",
    "print(\"Photo norm:\", n_m, \"/ per pixel:\", n_m/img1.size)\n",
    "print(\"Zero norm:\", n_0, \"/ per pixel:\", n_0*1.0/img1.size)\n",
    "\n",
    "print(n_m/img1.size*100)\n",
    "if(n_m/img1.size*100<27.5):\n",
    "    print(\"Images Are of same Person!\")\n",
    "else:\n",
    "    print(\"Images Are of Different People\")\n",
    "\n",
    "time2=time.time()\n",
    "ser_time=Time.timediffparsr(time2,time1)\n",
    "print(\"Time For Serial Execution - \",ser_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZarUacU7MGq"
   },
   "source": [
    "Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r91PCpRF2R6K",
    "outputId": "f73e79c1-7510-453b-89b5-e4d157a1186b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(600, 500)\n",
      "(847, 696)\n",
      "Photo norm: 85799.36754759874 / per pixel: 0.31566747809111284\n",
      "Zero norm: 271797.0 / per pixel: 0.9999779251884637\n",
      "31.566747809111284\n",
      "Images are of Different People\n",
      "Time For parallel Execution -  0.21193034574725528\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import Time   \n",
    "import time\n",
    "import cv2 as cv\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from scipy import misc\n",
    "import datetime\n",
    "import sys\n",
    "from scipy.misc import imread\n",
    "from scipy.linalg import norm\n",
    "from scipy import sum, average\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "print(num_cores)\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "face = misc.imread('photo1.jpg', cv.IMREAD_UNCHANGED)\n",
    "print (face.shape)\n",
    "face_cascade = cv.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "img = cv.imread('photo1.jpg')\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "(x, y, w, h)=(0,0,0,0)\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "frame = img[y:y+h, x:x+w]\n",
    "cv.imwrite('facecircledimg.jpg', img)\n",
    "\n",
    "cv.imwrite('face.jpg', frame)\n",
    "\n",
    "time1=time.time()\n",
    "\n",
    "img = cv.imread(\"face.jpg\")\n",
    "H,W = img.shape[:2]\n",
    "gray = np.zeros((H,W), np.uint8)\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    for i in range(H):\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            for j in range(W):\n",
    "                gray[i,j] = np.clip(0.07 * img[i,j,0]  + 0.72 * img[i,j,1] + 0.21 * img[i,j,2], 0, 255)\n",
    "cv.imwrite('Facegray.jpg', gray)\n",
    "\n",
    "face = misc.imread('photo2.jpg', cv.IMREAD_UNCHANGED)\n",
    "print (face.shape)\n",
    "face_cascade = cv.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "img = cv.imread('photo2.jpg')\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "frame = img[y:y+h, x:x+w]\n",
    "cv.imwrite('Face2.jpg', frame)\n",
    "cv.imwrite('facecircledimg1.jpg', img)\n",
    "\n",
    "\n",
    "img = cv.imread(\"Face2.jpg\")\n",
    "H,W = img.shape[:2]\n",
    "gray = np.zeros((H,W), np.uint8)\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    for i in range(H):\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            for j in range(W):\n",
    "                gray[i,j] = np.clip(0.07 * img[i,j,0]  + 0.72 * img[i,j,1] + 0.21 * img[i,j,2], 0, 255)\n",
    "cv.imwrite('Facegray2.jpg', gray)\n",
    "cv.waitKey()\n",
    "\n",
    "def normalize(arr):\n",
    "    rng = arr.max()-arr.min()\n",
    "    amin = arr.min()\n",
    "    return (arr-amin)*255/rng\n",
    "\n",
    "def compare_images(img1, img2):\n",
    "    img1 = normalize(img1)\n",
    "    img2 = normalize(img2)\n",
    "    diff = img1 - img2 \n",
    "    m_norm = sum(abs(diff))\n",
    "    z_norm = norm(diff.ravel(), 0) \n",
    "    return (m_norm, z_norm)\n",
    "\n",
    "img1=cv.imread(\"Facegray2.jpg\")\n",
    "img2=cv.imread(\"Facegray.jpg\")\n",
    "x=len(np.array(img1))\n",
    "y=len(np.array(img2))\n",
    "\n",
    "width = int(img1.shape[1]*y/x)\n",
    "height = int(img1.shape[0]*y/x)\n",
    "dim = (width, height)\n",
    "# resize image\n",
    "resized = cv.resize(img, dim, interpolation = cv.INTER_AREA)\n",
    "cv.imwrite('NewSizedImageGray.jpg',resized) \n",
    "\n",
    "img1=cv.imread(\"NewSizedImageGray.jpg\")\n",
    "n_m, n_0 = compare_images(img1, img2)\n",
    "print(\"Photo norm:\", n_m, \"/ per pixel:\", n_m/img1.size)\n",
    "print(\"Zero norm:\", n_0, \"/ per pixel:\", n_0*1.0/img1.size)\n",
    "\n",
    "print(n_m/img1.size*100)\n",
    "if(n_m/img1.size*100<27.5):\n",
    "    print(\"Images Are of same Person!\")\n",
    "else:\n",
    "    print(\"Images are of Different People\")\n",
    "\n",
    "time2=time.time()\n",
    "par_time=Time.timediffparnm(time2,time1)\n",
    "print(\"Time For parallel Execution - \",par_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O3rW3O_QQS-f",
    "outputId": "936f630d-c567-4a08-f18d-01ce99801876"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speedup Ratio for the program is 3.6423776077251673\n"
     ]
    }
   ],
   "source": [
    "print(\"Speedup Ratio for the program is\",ser_time/par_time)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PDC_Jcomp.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
